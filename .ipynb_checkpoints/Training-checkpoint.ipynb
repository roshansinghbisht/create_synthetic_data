{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ae2679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import config\n",
    "import cv2\n",
    "from utils import (\n",
    "    get_model_instance_segmentation,\n",
    "    collate_fn,\n",
    "    get_transform,\n",
    "    myOwnDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67b2e593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.11.0+cu102\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8293b1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# create own Dataset\n",
    "my_dataset = myOwnDataset(\n",
    "    root=config.train_data_dir, annotation=config.train_coco, transforms=get_transform()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a1eda69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "print(my_dataset.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d810f22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# own DataLoader\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    my_dataset,\n",
    "    batch_size=config.train_batch_size,\n",
    "    shuffle=config.train_shuffle_dl,\n",
    "    num_workers=config.num_workers_dl,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db5620b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "    \n",
    "# # obtain one batch of training images\n",
    "# dataiter = iter(data_loader)\n",
    "# images, labels = dataiter.next()\n",
    "# images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "# fig = plt.figure(figsize=(25, 4))\n",
    "# for idx in np.arange(5):\n",
    "#     ax = fig.add_subplot(2, 5/2, idx+1, xticks=[], yticks=[])\n",
    "#     ax.imshow(np.squeeze(image[idx]), cmap='gray')\n",
    "#     ax.set_title(classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eac4a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select device (whether GPU or CPU)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ba200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader is iterable over Dataset\n",
    "for imgs, annotations in data_loader:\n",
    "    imgs = list(img.to(device) for img in imgs)\n",
    "    print(imgs)\n",
    "    annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "#     print(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b709674",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model_instance_segmentation(config.num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d221ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params, lr=config.lr, momentum=config.momentum, weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "len_dataloader = len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a1d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(config.num_epochs):\n",
    "    print(f\"Epoch: {epoch}/{config.num_epochs}\")\n",
    "    model.train()\n",
    "    i = 0\n",
    "    for imgs, annotations in data_loader:\n",
    "        i += 1\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "        loss_dict = model(imgs, annotations)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Iteration: {i}/{len_dataloader}, Loss: {losses}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
